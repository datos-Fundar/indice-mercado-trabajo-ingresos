{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "pathdata = '/home/daniu/Documentos/fundar/indice-mercado-trabajo-ingresos/'\n",
    "pathdata = '/Users/danielarisaro/Documents/fundar/indice-mercado-trabajo-ingresos/'\n",
    "pathdata = '/home/daniufundar/Documents/Fundar/indice-mercado-trabajo-ingresos/'\n",
    "\n",
    "df_people_2021 = pd.read_csv(pathdata + 'data_input/personas_tot_urb_3T_21.txt', delimiter=';', low_memory=False)\n",
    "df_people_2022 = pd.read_csv(pathdata + 'data_input/personas_tot_urb_3T_22.txt', delimiter=';', low_memory=False)\n",
    "\n",
    "df_houses_2021 = pd.read_csv(pathdata + 'data_input/hogar_tot_urb_3T_2021.txt', delimiter=';', low_memory=False)\n",
    "df_houses_2022 = pd.read_csv(pathdata + 'data_input/hogar_tot_urb_3T_2022.txt', delimiter=';', low_memory=False)\n",
    "\n",
    "df_CBT = pd.read_csv(pathdata + 'data_output/Canasta_Basica_Total_Regiones_2016-2022-promedios-moviles.csv', delimiter=',', header=0, index_col=[0])\n",
    "df_adultos_equiv = pd.read_csv(pathdata + 'data_input/canastas_basicas/adultos_equivalente.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_provincia\n",
    "dict_cod_provincia = {2: \"Ciudad Autónoma de Buenos Aires\",\n",
    " 6: \"Buenos Aires\",\n",
    " 10: \"Catamarca\",\n",
    " 14: \"Córdoba\",\n",
    " 18: \"Corrientes\",\n",
    " 22: \"Chaco\",\n",
    " 26: \"Chubut\",\n",
    " 30: \"Entre Ríos\",\n",
    " 34: \"Formosa\",\n",
    " 38: \"Jujuy\",\n",
    " 42: \"La Pampa\",\n",
    " 46: \"La Rioja\",\n",
    " 50: \"Mendoza\",\n",
    " 54: \"Misiones\",\n",
    " 58: \"Neuquén\",\n",
    " 62: \"Río Negro\",\n",
    " 66: \"Salta\",\n",
    " 70: \"San Juan\",\n",
    " 74: \"San Luis\",\n",
    " 78: \"Santa Cruz\",\n",
    " 82: \"Santa Fe\",\n",
    " 86: \"Santiago del Estero\",\n",
    " 90: \"Tucumán\",\n",
    " 94: \"Tierra del Fuego, Antártida e Islas del Atlántico Sur\"}\n",
    "#cod_aglomerado\n",
    "\n",
    "dict_cod_aglomerado = {2: \"Gran La Plata\",\n",
    "3: \"Bahía Blanca - Cerri\",\n",
    "4: \"Gran Rosario\",\n",
    "5: \"Gran Santa Fé\",\n",
    "6: \"Gran Paraná\",\n",
    "7: \"Posadas\",\n",
    "8: \"Gran Resistencia\",\n",
    "9: \"Comodoro Rivadavia - Rada Tilly\",\n",
    "10:\" Gran Mendoza\",\n",
    "12: \"Corrientes\",\n",
    "13: \"Gran Córdoba\",\n",
    "14: \"Concordia\",\n",
    "15: \"Formosa\",\n",
    "17: \"Neuquén – Plottier\",\n",
    "18: \"Santiago del Estero - La Banda\",\n",
    "19: \"Jujuy-Palpalá\",\n",
    "20: \"Río Gallegos\",\n",
    "22: \"Gran Catamarca\",\n",
    "23: \"Gran Salta\",\n",
    "25: \"La Rioja\",\n",
    "26: \"Gran San Luis\",\n",
    "27: \"Gran San Juan\",\n",
    "29: \"Gran Tucumán - Tafí Viejo\",\n",
    "30: \"Santa Rosa – Toay\",\n",
    "31: \"Ushuaia - Río Grande\",\n",
    "32: \"Ciudad Autónoma de Buenos Aires\",\n",
    "33: \"Partidos del GBA\",\n",
    "34: \"Mar del Plata\",\n",
    "36: \"Río Cuarto\",\n",
    "38: \"San Nicolás – Villa Constitución\",\n",
    "91: \"Rawson – Trelew\",\n",
    "93: \"Viedma – Carmen de Patagones\",\n",
    "40: 'Resto Buenos Aires',\n",
    "41: 'Resto Catamarca',\n",
    "42: 'Resto Córdoba',\n",
    "43: 'Resto Corrientes',\n",
    "44: 'Resto Chaco',\n",
    "45: 'Resto Chubut',\n",
    "46: 'Resto Entre Ríos',\n",
    "47: 'Resto Formosa',\n",
    "48: 'Resto Jujuy',\n",
    "49: 'Resto La Pampa',\n",
    "50: 'Resto La Rioja',\n",
    "51: 'Resto Mendoza',\n",
    "52: 'Resto Misiones',\n",
    "53: 'Resto Neuquén',\n",
    "54: 'Resto Río Negro',\n",
    "55: 'Resto Salta',\n",
    "56: 'Resto San Juan',\n",
    "57: 'Resto San Luis',\n",
    "58: 'Resto Santa Cruz',\n",
    "60: 'Resto Santa Fe',\n",
    "61: 'Resto Santiago del Estero',\n",
    "62: 'Resto Tucumán'}\n",
    "\n",
    "# Agrego regiones\n",
    "prov_regiones = pd.DataFrame([\n",
    "['Ciudad Autónoma de Buenos Aires','CABA', 'Pampeana'],\n",
    "['Buenos Aires','BA', 'Pampeana'],\n",
    "['Neuquén', 'NQN', 'Patagonia'],\n",
    "['Córdoba', 'CBA','Pampeana'],\n",
    "['San Luis', 'SL', 'Cuyo'],\n",
    "['Santa Fe', 'SF','Pampeana'],\n",
    "['Misiones', 'MIS', 'Noreste'],\n",
    "['La Rioja', 'LR', 'Noroeste'],\n",
    "['Mendoza', 'MZA', 'Cuyo'],\n",
    "['Tucumán', 'TUC', 'Noroeste'],\n",
    "['Tierra del Fuego, Antártida e Islas del Atlántico Sur', 'TDF', 'Patagonia'],\n",
    "['Entre Ríos', 'ER','Pampeana'],\n",
    "['La Pampa', 'LP','Pampeana'],\n",
    "['Chaco', 'CHA', 'Noreste'],\n",
    "['Río Negro', 'RN', 'Patagonia'],\n",
    "['San Juan', 'SJ', 'Cuyo'],\n",
    "['Corrientes', 'COR', 'Noreste'],\n",
    "['Santiago del Estero', 'SE','Noroeste'],\n",
    "['Catamarca', 'CAT', 'Noroeste'],\n",
    "['Salta', 'SAL', 'Noroeste'],\n",
    "['Formosa', 'FOR', 'Noreste'],\n",
    "['Chubut', 'CHU', 'Patagonia'],\n",
    "['Santa Cruz', 'SC', 'Patagonia'],\n",
    "['Jujuy', 'JU', 'Noroeste']], columns=['Provincia', 'Etiqueta', 'Region'])\n",
    "prov_regiones = prov_regiones.set_index('Provincia')\n",
    "\n",
    "map_provincia_region = prov_regiones['Region'].to_dict()\n",
    "\n",
    "# Agrego regiones\n",
    "aglom_regiones = pd.DataFrame([\n",
    "[\"Gran La Plata\", 'Pampeana'],\n",
    "[\"Bahía Blanca - Cerri\", 'Pampeana'],\n",
    "[\"Gran Rosario\", 'Pampeana'],\n",
    "[\"Gran Santa Fé\", 'Pampeana'],\n",
    "[\"Gran Paraná\", 'Pampeana'],\n",
    "[\"Posadas\", 'Noreste'],\n",
    "[\"Gran Resistencia\", 'Noreste'],\n",
    "[\"Comodoro Rivadavia - Rada Tilly\", 'Patagonia'],\n",
    "[\"Gran Mendoza\", 'Cuyo'],\n",
    "[\"Corrientes\", 'Noreste'],\n",
    "[\"Gran Córdoba\", 'Pampeana'],\n",
    "[\"Concordia\", 'Pampeana'],\n",
    "[\"Formosa\", 'Noreste'],\n",
    "[\"Neuquén – Plottier\", 'Patagonia'],\n",
    "[\"Santiago del Estero - La Banda\", 'Noroeste'],\n",
    "[\"Jujuy-Palpalá\", 'Noroeste'],\n",
    "[\"Río Gallegos\", 'Patagonia'],\n",
    "[\"Gran Catamarca\", 'Noroeste'],\n",
    "[\"Gran Salta\", 'Noroeste'],\n",
    "[\"La Rioja\", 'Noroeste'],\n",
    "[\"Gran San Luis\", 'Cuyo'],\n",
    "[\"Gran San Juan\", 'Cuyo'],\n",
    "[\"Gran Tucumán - Tafí Viejo\", 'Noroeste'],\n",
    "[\"Santa Rosa – Toay\", 'Pampeana'],\n",
    "[\"Ushuaia - Río Grande\", 'Patagonia'],\n",
    "[\"Ciudad Autónoma de Buenos Aires\", 'Gran Buenos Aires'],\n",
    "[\"Partidos del GBA\", 'Gran Buenos Aires'],\n",
    "[\"Mar del Plata\", 'Pampeana'],\n",
    "[\"Río Cuarto\", 'Pampeana'],\n",
    "[\"San Nicolás – Villa Constitución\", 'Pampeana'],\n",
    "[\"Rawson – Trelew\", 'Patagonia'],\n",
    "[\"Viedma – Carmen de Patagones\" 'Patagonia'],\n",
    "['Resto Buenos Aires', 'Pampeana'],\n",
    "['Resto Catamarca', 'Noroeste'],\n",
    "['Resto Córdoba', 'Pampeana'],\n",
    "['Resto Corrientes', 'Noreste'],\n",
    "['Resto Chaco', 'Noreste'],\n",
    "['Resto Chubut', 'Patagonia'],\n",
    "['Resto Entre Ríos', 'Pampeana'],\n",
    "['Resto Formosa', 'Noreste'],\n",
    "['Resto Jujuy', 'Noroeste'],\n",
    "['Resto La Pampa', 'Pampeana'],\n",
    "['Resto La Rioja', 'Noroeste'],\n",
    "['Resto Mendoza', 'Cuyo'],\n",
    "['Resto Misiones', 'Noreste'],\n",
    "['Resto Neuquén', 'Patagonia'],\n",
    "['Resto Río Negro', 'Patagonia'],\n",
    "['Resto Salta', 'Noroeste'],\n",
    "['Resto San Juan', 'Cuyo'],\n",
    "['Resto San Luis', 'Cuyo'],\n",
    "['Resto Santa Cruz', 'Patagonia'],\n",
    "['Resto Santa Fe', 'Pampeana'],\n",
    "['Resto Santiago del Estero', 'Noroeste'],\n",
    "['Resto Tucumán', 'Noroeste'],],\n",
    "columns=['Aglomerado', 'Region'])\n",
    "\n",
    "aglom_regiones = aglom_regiones.set_index('Aglomerado')\n",
    "\n",
    "map_aglomerado_region = aglom_regiones['Region'].to_dict()\n",
    "\n",
    "def capitalize_first_letter(s):\n",
    "    return s.capitalize()\n",
    "\n",
    "df_CBT = df_CBT.rename(columns=capitalize_first_letter)\n",
    "df_CBT.rename(columns={'Gran_buenos_aires':'Gran Buenos Aires'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 30417\n",
      "Left-only rows: 48100\n",
      "Right-only rows: 47523\n",
      "La longitud de los dataframes con y sin replicas son (155859, 127958)\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df_people_2021[['CODUSU', 'COMPONENTE']], df_people_2022[['CODUSU', 'COMPONENTE']], on=['CODUSU', 'COMPONENTE'], how='outer', indicator=True)\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "duplicated_rows = merged_df['_merge'].value_counts()['both']\n",
    "print(f\"Number of duplicate rows: {duplicated_rows}\")\n",
    "\n",
    "# Display the left-only rows (2021)\n",
    "left_only_rows = merged_df['_merge'].value_counts()['left_only']\n",
    "print(f\"Left-only rows: {left_only_rows}\")\n",
    "\n",
    "# Display the right-only rows (2022)\n",
    "right_only_rows = merged_df['_merge'].value_counts()['right_only']\n",
    "print(f\"Right-only rows: {right_only_rows}\")\n",
    "\n",
    "# Select the right-only and right observation from both rows in merged_df\n",
    "right_only_rows = merged_df[merged_df['_merge'] == 'right_only']\n",
    "left_only_rows = merged_df[merged_df['_merge'] == 'left_only']\n",
    "both_rows = merged_df[merged_df['_merge'] == 'both']\n",
    "right_both_rows = pd.concat([both_rows, right_only_rows])\n",
    "\n",
    "# Option 1: Merge two dataframes with \"copies\"\n",
    "df_people_2021['rel_PONDERA'] = df_people_2021['PONDERA']/df_people_2021['PONDERA'].sum()\n",
    "df_people_2022['rel_PONDERA'] = df_people_2022['PONDERA']/df_people_2022['PONDERA'].sum()\n",
    "\n",
    "df_merged_with_copies = pd.concat([df_people_2021, df_people_2022])\n",
    "\n",
    "# Option 2: Merge two dataframes erasing the first copy (keeping right only and right both observations)\n",
    "df_people_2021_no_dupl = pd.merge(left_only_rows, df_people_2021, on=[\"CODUSU\", \"COMPONENTE\"], how='inner')\n",
    "df_people_2022_no_dupl = pd.merge(right_both_rows, df_people_2022, on=[\"CODUSU\", \"COMPONENTE\"], how='inner')\n",
    "\n",
    "df_merged_without_copies = pd.concat([df_people_2021_no_dupl, df_people_2022_no_dupl])\n",
    "\n",
    "\n",
    "# Length of resulting dataframes\n",
    "n_with_copies = len(df_merged_with_copies)\n",
    "n_without_copies = len(df_merged_without_copies)\n",
    "print(f\"La longitud de los dataframes con y sin replicas son {n_with_copies, n_without_copies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# T5. \n",
    "# Variable: Horas trabajadas en el hogar\n",
    "# Indicador: Ratio M/V en Horas semanales promedio destinadas al TNR en el hogar\n",
    "\n",
    "        # en funcion de la enut\n",
    "\n",
    "\n",
    "# Componente: Autonomía económica\n",
    "\n",
    "# T6. \n",
    "# Variable: Dependencia económica \n",
    "# Indicador: Ratio M/V en Población inactiva y que no estudia sin ingresos propios\n",
    "\n",
    "def ratio_tasa_poblacion_dependiente(df, tipo='Aglomerado', base='Individual'):\n",
    "\n",
    "    # En este caso dividir el indicador segun algun percentil de ingresos. Por ejemplo de 90 a 60. Ver literatura al respecto \n",
    "\n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    df: DataFrame. Tabla input EPH\n",
    "    tipo: string. Tipo de encuesta de la EPH, Aglomerado o Urbano. Default Aglomerado\n",
    "    base: string. Tipo de base de la encuesta de la EPH, Individual u Hogar. Default Individual\n",
    "\n",
    "    OUTPUTS\n",
    "    ratio: DataFrame. Tabla con Ratios en tasa M/V de población inactiva que no estudia y no tiene ingresos propios, desagregado por Aglomerado o Provincia\n",
    "    error: DataFrame. Tabla con los errores asociados a los Ratios\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the necessary columns exist in the input DataFrame\n",
    "    if not all(col in df.columns for col in ['CH04', 'CH06', 'ESTADO', 'PONDERA', 'P47T', 'CH10', 'PONDII']):\n",
    "        raise ValueError(\"The input DataFrame must have the following columns: 'CH04', 'CH06', 'ESTADO', 'PONDERA', 'P47T', 'CH10', 'PONDII'\")\n",
    "        \n",
    "    # Check if the input value of \"tipo\" is valid\n",
    "    if tipo not in ['Aglomerado', 'Urbano']:\n",
    "        return None, 'Error: tipo debe ser \"Aglomerado\" o \"Urbano\"'\n",
    "    if base not in ['Individual', 'Hogar']:\n",
    "        return None, 'Error: base debe ser \"Individual\" o \"Hogar\"'\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        return None, 'Error: df debe ser un DataFrame de pandas'\n",
    "    \n",
    "    if tipo=='Aglomerado':\n",
    "        var = 'AGLOMERADO' \n",
    "    elif tipo=='Urbano':\n",
    "        var = 'PROVINCIA'\n",
    "\n",
    "    df_temp = df.query('CH06 >= 16 & CH06 < 65')\n",
    "\n",
    "    numerador = df_temp[(df_temp['ESTADO']==3) & (df_temp['P47T']==0) & (df_temp['CAT_INAC']!=3)].groupby(['CH04', var])['PONDII'].sum()\n",
    "    \n",
    "    size = df_temp[(df_temp['ESTADO']==3) & (df_temp['P47T']==0) & (df_temp['CAT_INAC']!=3)].groupby(['CH04', var]).size().to_frame().unstack(level=0)\n",
    "    size.columns = size.columns.get_level_values(1)\n",
    "    \n",
    "    denominador = df_temp.groupby(['CH04', var])['PONDERA'].sum()\n",
    "    df_tasa = (numerador / denominador).to_frame().unstack(level=0)                         # calculo tasa\n",
    "\n",
    "    ratio = (df_tasa[0][2]/df_tasa[0][1] * 100).to_frame()\n",
    "    ratio.rename(columns={0: 'Dependencia económica'}, inplace=True)\n",
    "\n",
    "    ratio = ratio.join(size)\n",
    "    ratio.rename(columns={1: 'N_v', 2: 'N_m'}, inplace=True)\n",
    "\n",
    "    error = pd.DataFrame(index=ratio.index)\n",
    "    error = 'a definir'\n",
    "\n",
    "\n",
    "    return ratio, error\n",
    "\n",
    "# T7.                                   # TODO: ajustar con IPC\n",
    "# Variable: Ingreso salarial\n",
    "# Indicador: Ratio M/V en Ingreso salarial promedio mensual\n",
    "\n",
    "def ratio_ingreso_laboral_mensual(df, tipo='Aglomerado', base='Individual'):\n",
    "\n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    df: DataFrame. Tabla input EPH\n",
    "    tipo: string. Tipo de encuesta de la EPH, Aglomerado o Urbano. Default Aglomerado\n",
    "    base: string. Tipo de base de la encuesta de la EPH, Individual u Hogar. Default Individual\n",
    "\n",
    "    OUTPUTS\n",
    "    ratio: DataFrame. Tabla con Ratios del ingreso individual mensual laboral de M/V, desagregado por Aglomerado o Provincia\n",
    "    error: DataFrame. Tabla con los errores asociados a los Ratios\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tipo=='Aglomerado':\n",
    "        var = 'AGLOMERADO' \n",
    "    elif tipo=='Urbano':\n",
    "        var = 'PROVINCIA'\n",
    "\n",
    "    df_temp = df.query('CH06 >= 16 & CH06 < 65')\n",
    "    df_estado = df_temp[(df_temp['ESTADO'] == 1) & (~df_temp['CAT_OCUP'].isin([1, 4, 9]))]\n",
    "\n",
    "    df_ingreso = df_estado[(df_estado['P21']>0) & (df_estado['P21']!=-9)].sum()\n",
    "    df_tasa = df_ingreso.groupby(['CH04', var])['PONDIIO'].median().to_frame().unstack(level=0)  \n",
    "    \n",
    "    ratio = (df_tasa['PONDIIO'][2]/df_tasa['PONDIIO'][1] * 100).to_frame()\n",
    "    ratio.rename(columns={0: 'Ingreso laboral'}, inplace=True)\n",
    "    \n",
    "    ratio = ratio.join(size)\n",
    "    ratio.rename(columns={1: 'N_v', 2: 'N_m'}, inplace=True)\n",
    "\n",
    "    error = 'a definir'\n",
    "\n",
    "    return ratio, error\n",
    "\n",
    "\n",
    "# T8.                               # TODO: ver definicion monoparentalidad\n",
    "# Variable: Pobreza\n",
    "# Indicador: Ratio M/V en Población con ingreso total individual inferior a LP\n",
    "\n",
    "def ratio_pobreza(df, CBT, tipo='Aglomerado', base='Individual'):\n",
    "\n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    df: DataFrame. Tabla input EPH\n",
    "    tipo: string. Tipo de encuesta de la EPH, Aglomerado o Urbano. Default Aglomerado\n",
    "    base: string. Tipo de base de la encuesta de la EPH, Individual u Hogar. Default Individual\n",
    "\n",
    "    OUTPUTS\n",
    "    ratio: DataFrame. Tabla con Ratios del ingreso individual mensual laboral de M/V, desagregado por Aglomerado o Provincia\n",
    "    error: DataFrame. Tabla con los errores asociados a los Ratios\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if tipo=='Aglomerado':\n",
    "        var = 'AGLOMERADO' \n",
    "    elif tipo=='Urbano':\n",
    "        var = 'PROVINCIA'\n",
    "\n",
    "    df_temp = df.query('CH06 >= 16 & CH06 < 65')\n",
    "    df_estado = df_temp[(df_temp['ESTADO'] == 1) & (~df_temp['CAT_OCUP'].isin([1, 4, 9]))]\n",
    "\n",
    "    numerador = df_estado[(df_estado['P21']>0) & (df_estado['P21']!=-9)].sum()\n",
    "    denominador = 'TBD'\n",
    "    df_tasa = df_estado.groupby(['CH04', var])['PONDIIO'].mean().to_frame().unstack(level=0)  \n",
    "    \n",
    "    ratio = (df_tasa['PONDIIO'][2]/df_tasa['PONDIIO'][1] * 100).to_frame()\n",
    "    ratio.rename(columns={0: 'Ingreso laboral'}, inplace=True)\n",
    "    \n",
    "    error = 'a definir'\n",
    "\n",
    "    return ratio, error\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "509f5cbefa0cafc10dc1461472345186404cff510fb444dcb85013f09977a5b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
